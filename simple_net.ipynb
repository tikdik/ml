{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "accuracy on test_dataset 0.9072\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST-data', one_hot=True)\n",
    "\n",
    "X = tf.placeholder(\"float\",[None, 784])\n",
    "Y_ = tf.placeholder(\"float\",[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([784,10], stddev=0.1))\n",
    "B = tf.Variable(tf.truncated_normal([10], stddev=0.1))\n",
    "\n",
    "L1 = tf.matmul(X, W) + B\n",
    "Y = tf.nn.softmax(L1)\n",
    "\n",
    "loss = -tf.reduce_sum(Y_ * tf.log(Y)) #交叉熵cross_entropy\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss) #梯度下降法 最小化损失函数\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #r = sess.run(Y, feed_dict={X:mnist.train.images[:1]}) 直接预测 发现结果为[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
    "    for i in range(1000):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(100) #从总体训练中提取一批进行训练，可以优化参数\n",
    "        sess.run(optimizer, feed_dict={X:batch_xs, Y_:batch_ys})\n",
    "#     p = sess.run(Y, feed_dict={X:mnist.test.images[:1]})  #看图验证结果\n",
    "#     print(p)\n",
    "#     print(tf.argmax(p,1))\n",
    "#     plt.imshow(np.asarray(mnist.test.images[0]).reshape(28,28))\n",
    "#     plt.show()\n",
    "    correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"accuracy on test_dataset\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y_:mnist.test.labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d6e75f96eef0>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "[[1.0517460e-09 9.2462510e-14 2.0627058e-07 4.4273284e-07 9.2933398e-13\n",
      "  3.5048542e-09 1.9418963e-15 9.9999928e-01 2.4492655e-10 7.7947622e-09]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test_dataset 0.9667818\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST-data') #, one_hot=True)\n",
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    X = tf.placeholder(\"float\",[None, 784])\n",
    "    Y_ = tf.placeholder(tf.int64,[None])\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.truncated_normal([784,500], stddev=0.1))\n",
    "    B1 = tf.Variable(tf.truncated_normal([500], stddev=0.1))\n",
    "\n",
    "    N1 = tf.matmul(X, W1) + B1\n",
    "    L1 = tf.nn.relu(N1)\n",
    "with tf.name_scope('dropout'):\n",
    "    dropped = tf.nn.dropout(L1, tf.constant(1.0))\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.truncated_normal([500,10], stddev=0.1))\n",
    "    B2 = tf.Variable(tf.truncated_normal([10], stddev=0.1))\n",
    "\n",
    "    N2 = tf.matmul(dropped, W2) + B2\n",
    "    N21 = tf.identity(N2)\n",
    "    Y = tf.nn.softmax(N21)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    #loss = -tf.reduce_sum(Y_ * tf.log(Y)) #交叉熵cross_entropy\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=Y_, logits=Y)\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss) #梯度下降法 最小化损失函数\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #r = sess.run(Y, feed_dict={X:mnist.train.images[:1]}) 直接预测 发现结果为[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
    "    for i in range(1000):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(100) #从总体训练中提取一批进行训练，可以优化参数\n",
    "        sess.run(optimizer, feed_dict={X:batch_xs, Y_:batch_ys})\n",
    "    p = sess.run(Y, feed_dict={X:mnist.test.images[:1]})  #看图验证结果\n",
    "    print(p)\n",
    "    plt.imshow(np.asarray(mnist.test.images[0]).reshape(28,28))\n",
    "    plt.show()\n",
    "    correct_prediction = tf.equal(tf.argmax(Y,1), Y_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"accuracy on test_dataset\", sess.run(accuracy, feed_dict={X:mnist.train.images, Y_:mnist.train.labels}))\n",
    "    tf.summary.FileWriter('./logs', sess.graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-fbb5f5286182>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "accuracy on test_dataset 0.16267273\n",
      "accuracy on test_dataset 0.7494\n",
      "accuracy on test_dataset 0.8443091\n",
      "accuracy on test_dataset 0.87243634\n",
      "accuracy on test_dataset 0.8867273\n",
      "accuracy on test_dataset 0.89543635\n",
      "accuracy on test_dataset 0.9028909\n",
      "accuracy on test_dataset 0.9043818\n",
      "accuracy on test_dataset 0.91114545\n",
      "accuracy on test_dataset 0.91276366\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n",
      "WARNING:tensorflow:From <ipython-input-1-fbb5f5286182>:53: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST-data', one_hot=True)\n",
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    X = tf.placeholder(\"float\",[None, 784], name=\"x\")\n",
    "    Y_ = tf.placeholder(\"float\",[None, 10], name=\"y\")\n",
    "\n",
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name=\"layer\", act=tf.nn.relu):\n",
    "    with tf.name_scope(layer_name):\n",
    "        W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name=\"weight\")\n",
    "        B = tf.Variable(tf.truncated_normal([output_dim], stddev=0.1), name=\"bias\")\n",
    "\n",
    "        N = tf.matmul(input_tensor, W) + B\n",
    "        Out = act(N)\n",
    "        return Out\n",
    "layer1 = nn_layer(X, 784, 500, \"layer1\")\n",
    "layer2 = nn_layer(layer1, 500, 10, \"layer2\", tf.identity)\n",
    "\n",
    "Y = tf.nn.softmax(layer2, name=\"output\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    loss = -tf.reduce_sum(Y_ * tf.log(Y)) #交叉熵cross_entropy\n",
    "    #loss = tf.losses.sparse_softmax_cross_entropy(labels=Y_, logits=Y)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss) #梯度下降法 最小化损失函数\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    log = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(100) #从总体训练中提取一批进行训练，可以优化参数\n",
    "        summary,_ = sess.run([merged, optimizer], feed_dict={X:batch_xs, Y_:batch_ys})\n",
    "        log.add_summary(summary, i)\n",
    "        if i % 10 == 0:\n",
    "            summary,ac = sess.run([merged,accuracy], feed_dict={X:mnist.train.images, Y_:mnist.train.labels})\n",
    "            print(\"accuracy on test_dataset\", ac)\n",
    "            log.add_summary(summary, i)\n",
    "    #save model\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['output'])\n",
    "    with tf.gfile.FastGFile('./tf-model/model.pb', mode='wb') as f:\n",
    "        f.write(constant_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "cluster=tf.train.ClusterSpec({\n",
    "    \"worker\": [\n",
    "        \"192.168.35.116:1234\",\n",
    "    ],\n",
    "    \"ps\": [\n",
    "        \"192.168.35.115:1234\"\n",
    "    ]})\n",
    "\n",
    "isps=False\n",
    "if isps:\n",
    "        server=tf.train.Server(cluster,job_name='ps',task_index=0)\n",
    "        server.join()\n",
    "else:\n",
    "        server=tf.train.Server(cluster,job_name='worker',task_index=0)\n",
    "        with tf.device(tf.train.replica_device_setter(worker_device='/job:worker/task:0',cluster=cluster)):\n",
    "\n",
    "            mnist = input_data.read_data_sets('MNIST-data', one_hot=True)\n",
    "\n",
    "            with tf.name_scope(\"input\"):\n",
    "                X = tf.placeholder(\"float\",[None, 784], name=\"x\")\n",
    "                Y_ = tf.placeholder(\"float\",[None, 10], name=\"y\")\n",
    "\n",
    "            def nn_layer(input_tensor, input_dim, output_dim, layer_name=\"layer\", act=tf.nn.relu):\n",
    "                with tf.name_scope(layer_name):\n",
    "                    W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name=\"weight\")\n",
    "                    B = tf.Variable(tf.truncated_normal([output_dim], stddev=0.1), name=\"bias\")\n",
    "\n",
    "                    N = tf.matmul(input_tensor, W) + B\n",
    "                    Out = act(N)\n",
    "                    return Out\n",
    "            layer1 = nn_layer(X, 784, 500, \"layer1\")\n",
    "            layer2 = nn_layer(layer1, 500, 10, \"layer2\", tf.identity)\n",
    "\n",
    "            Y = tf.nn.softmax(layer2, name=\"output\")\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                loss = -tf.reduce_sum(Y_ * tf.log(Y)) #交叉熵cross_entropy\n",
    "                #loss = tf.losses.sparse_softmax_cross_entropy(labels=Y_, logits=Y)\n",
    "                tf.summary.scalar('loss', loss)\n",
    "                optimizer = tf.train.AdamOptimizer(0.001).minimize(loss) #梯度下降法 最小化损失函数\n",
    "\n",
    "            with tf.name_scope(\"accuracy\"):\n",
    "                correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "sv = tf.train.Supervisor(init_op=init, summary_op=merged, saver=saver)\n",
    "with sv.prepare_or_wait_for_session(server.target) as sess:\n",
    "    log = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(100) #从总体训练中提取一批进行训练，可以优化参数\n",
    "        summary,_ = sess.run([merged, optimizer], feed_dict={X:batch_xs, Y_:batch_ys})\n",
    "        log.add_summary(summary, i)\n",
    "        if i % 10 == 0:\n",
    "            summary,ac = sess.run([merged,accuracy], feed_dict={X:mnist.train.images, Y_:mnist.train.labels})\n",
    "            print(\"accuracy on test_dataset\", ac)\n",
    "            log.add_summary(summary, i)\n",
    "    #save model\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['output'])\n",
    "    with tf.gfile.FastGFile('./tf-model/model.pb', mode='wb') as f:\n",
    "        f.write(constant_graph.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
